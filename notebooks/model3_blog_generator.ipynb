{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f7c8c8",
   "metadata": {},
   "source": [
    "## Generate blogposts for all categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f8fe3",
   "metadata": {},
   "source": [
    "# Blog-style Text Generator using Pre-trained Language Model\n",
    "This notebook generates blog-like summaries that help users choose among products.\n",
    "It takes clustered product data and creates human-readable reviews using a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(new_session=False)\n",
    "\n",
    "\n",
    "#!pip install git+https://github.com/huggingface/accelerate.git\n",
    "#!pip install git+https://github.com/huggingface/transformers.git\n",
    "#!pip install BitsAndBytes\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "hf_key = os.getenv(\"HF_KEY\") # We need our Hugging Face API key to access gated models\n",
    "\n",
    "model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# To minimize memory usage, without giving up precision, we will use 8-bit quantization instead of 32 with BitsAndBytesConfig\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_quant_type=\"nf8\",\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "# Load the quantized model and tokenizer\n",
    "blog_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    use_auth_token=hf_key\n",
    ")\n",
    "blog_tokenizer = AutoTokenizer.from_pretrained(model_path, use_auth_token=hf_key)\n",
    "\n",
    "# Save the blog generator model and tokenizer locally\n",
    "blog_model.save_pretrained('blog_generator')\n",
    "blog_tokenizer.save_pretrained('blog_generator')\n",
    "\n",
    "def generate_blogposts_for_all_categories(\n",
    "    df,\n",
    "    generator,\n",
    "    n_shot_prompt=None,\n",
    "    n_top_products=3,\n",
    "    n_complaints=2,\n",
    "    max_new_tokens=800,\n",
    "    temperature=0.4,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1\n",
    "):\n",
    "    from nltk.corpus import stopwords\n",
    "    from collections import Counter\n",
    "\n",
    "    # Set up text generation pipeline\n",
    "    #generator = pipeline(\"text-generation\", model=model, tokenizer=blog_tokenizer)  # Use device=0 for GPU, -1 for CPU\n",
    "\n",
    "    # Map sentiment labels to numeric scores\n",
    "    sentiment_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "    df['sentiment_points'] = df['sentiment'].map(sentiment_map)\n",
    "    blogposts = []\n",
    "    def get_top_complaints(df, product_name, n=n_complaints):\n",
    "        neg_reviews = df[(df['name'] == product_name) & (df['sentiment'] == 'negative')]['combined_reviews']\n",
    "        words = ' '.join(neg_reviews).split()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_words = [w.lower() for w in words if w.lower() not in stop_words and len(w) > 2]\n",
    "        most_common = Counter(filtered_words).most_common(n)\n",
    "        return [word for word, _ in most_common]\n",
    "\n",
    "    n_shot_prompt = \"\"\"\n",
    "# Context:\n",
    "You are a helpful assistant that writes concise, well-structured blogposts comparing consumer tech products. The user provides product review summaries, and you respond with a styled blogpost including top picks, key complaints, and a warning about the worst-rated product.\n",
    "\n",
    "## Example 1\n",
    "\n",
    "<|system|>\n",
    "You are a product review blogger assistant.\n",
    "\n",
    "<|user|>\n",
    "Write a blogpost based on review data for e-readers:\n",
    "1. Kindle Paperwhite (Avg. Rating: 4.8, 1200 reviews)\n",
    "   Complaints: screen glare, slow refresh\n",
    "2. Kobo Clara HD (Avg. Rating: 4.7, 950 reviews)\n",
    "   Complaints: limited store, battery life\n",
    "3. Kindle Oasis (Avg. Rating: 4.6, 800 reviews)\n",
    "   Complaints: price, weight\n",
    "Worst: Nook GlowLight 3 (Avg. Rating: 3.2), Complaints: slow performance, software glitches\n",
    "\n",
    "<|assistant|>\n",
    "--- Blogpost for E-readers ---\n",
    "Looking for the perfect e-reader? Here are our top picks!\n",
    "\n",
    "1. **Kindle Paperwhite** (Avg. Rating: 4.8, 1200 reviews)  \n",
    "   *Top complaints:* screen glare, slow refresh\n",
    "\n",
    "2. **Kobo Clara HD** (Avg. Rating: 4.7, 950 reviews)  \n",
    "   *Top complaints:* limited store, battery life\n",
    "\n",
    "3. **Kindle Oasis** (Avg. Rating: 4.6, 800 reviews)  \n",
    "   *Top complaints:* price, weight\n",
    "\n",
    "The **Kindle Paperwhite** stands out for its crisp display and waterproof design, making it ideal for reading anywhere. **Kobo Clara HD** is a great alternative with support for multiple formats, though some users wish for a larger store. The **Kindle Oasis** offers premium features, but its higher price and weight are noted by some reviewers.\n",
    "\n",
    "**Worst product:** Nook GlowLight 3 (Avg. Rating: 3.2)  \n",
    "Many customers report slow performance and frequent software glitches. Unless youâ€™re a die-hard Nook fan, we recommend considering other options for a smoother reading experience.\n",
    "\n",
    "---\n",
    "\n",
    "## Example 2\n",
    "\n",
    "<|user|>\n",
    "Write a blogpost using this tablet review data:\n",
    "1. iPad Air (4.9, 2100) - complaints: price, limited ports\n",
    "2. Galaxy Tab S7 (4.8, 1800) - complaints: bloatware, charger speed\n",
    "3. Fire HD 10 (4.5, 1600) - complaints: app selection, ads\n",
    "Worst: Lenovo Tab M8 (3.4) - complaints: sluggish, weak display\n",
    "\n",
    "<|assistant|>\n",
    "--- Blogpost for Smart Tablets ---\n",
    "Shopping for a smart tablet? Here are the top choices this year:\n",
    "\n",
    "1. **Apple iPad Air** (Avg. Rating: 4.9, 2100 reviews)  \n",
    "   *Top complaints:* price, limited ports\n",
    "\n",
    "2. **Samsung Galaxy Tab S7** (Avg. Rating: 4.8, 1800 reviews)  \n",
    "   *Top complaints:* bloatware, charger speed\n",
    "\n",
    "3. **Amazon Fire HD 10** (Avg. Rating: 4.5, 1600 reviews)  \n",
    "   *Top complaints:* app selection, ads\n",
    "\n",
    "The **iPad Air** is praised for its speed and display quality, though it comes at a premium. The **Galaxy Tab S7** offers excellent multitasking, but some users dislike the pre-installed apps. The **Fire HD 10** is a budget-friendly option, but its app ecosystem is more limited.\n",
    "\n",
    "**Worst product:** Lenovo Tab M8 (Avg. Rating: 3.4)  \n",
    "Users mention sluggish performance and a lackluster screen. For a better experience, consider one of the top-rated tablets above.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "    for category in df['clustered_category'].unique():\n",
    "        cat_df = df[df['clustered_category'] == category]\n",
    "        unique_products = cat_df['name'].nunique()\n",
    "        if unique_products == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute product scores for ranking (by sentiment_points)\n",
    "        product_scores = (\n",
    "            cat_df.groupby('name')['sentiment_points']\n",
    "            .agg(['mean', 'count'])\n",
    "            .sort_values(by=['mean', 'count'], ascending=[False, False])\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # For display: get average rating from 'reviews.rating'\n",
    "        avg_ratings = cat_df.groupby('name')['reviews.rating'].mean()\n",
    "\n",
    "        # Determine how many to show as top and which is worst\n",
    "        if unique_products == 1:\n",
    "            top_n = 1\n",
    "            show_worst = False\n",
    "        elif unique_products == 2:\n",
    "            top_n = 1\n",
    "            show_worst = True\n",
    "        elif unique_products == 3:\n",
    "            top_n = 2\n",
    "            show_worst = True\n",
    "        else:\n",
    "            top_n = 3\n",
    "            show_worst = True\n",
    "\n",
    "        top_products = product_scores.head(top_n)\n",
    "        if show_worst:\n",
    "            worst_product = product_scores.tail(1)\n",
    "        else:\n",
    "            worst_product = None\n",
    "\n",
    "        # Collect top complaints for top products\n",
    "        complaints = {\n",
    "            row['name']: get_top_complaints(cat_df, row['name'])\n",
    "            for _, row in top_products.iterrows()\n",
    "        }\n",
    "\n",
    "        # Compose the prompt\n",
    "        category_prompt = f\"\\n\\n### Blogpost:\\n\\n\"\n",
    "        category_prompt += f\"You are a product reviewer. Write a short, helpful blogpost for customers shopping for {category}.\\n\"\n",
    "        category_prompt += f\"- The top {top_n} product{'s are' if top_n > 1 else ' is'}:\\n\"\n",
    "\n",
    "        for i, row in top_products.iterrows():\n",
    "            name = row['name']\n",
    "            avg_rating = avg_ratings[name]\n",
    "            review_count = int(row['count'])\n",
    "            top_complaints = complaints[name]\n",
    "            complaint_text = ', '.join(top_complaints) if top_complaints else 'Few complaints!'\n",
    "            category_prompt += f\"{i+1}. {name} (Avg. Rating: {avg_rating:.2f}, {review_count} reviews)\\n\"\n",
    "            category_prompt += f\"   Top complaints: {complaint_text}\\n\"\n",
    "\n",
    "        # Include the worst product details if applicable\n",
    "        if show_worst and worst_product is not None:\n",
    "            worst_name = worst_product.iloc[0]['name']\n",
    "            worst_avg_rating = avg_ratings[worst_name]\n",
    "            category_prompt += f\"\\nThe worst product is {worst_name} (Avg. Rating: {worst_avg_rating:.2f}).\\n\"\n",
    "            category_prompt += \"Explain why customers should avoid the worst product from the category, based on reviews.\\n\"\n",
    "\n",
    "        category_prompt += \"Write the blog entry in a friendly, informative tone.\\n\"\n",
    "\n",
    "        prompt = n_shot_prompt + category_prompt\n",
    "        generated = generator(\n",
    "            prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            repetition_penalty=repetition_penalty\n",
    "        )[0]['generated_text']\n",
    "        blog_output = generated.split(\"Write the blog entry in a friendly, informative tone.\")[-1].strip()\n",
    "        blogposts.append(f\"--- Blogpost for {category} ---\\n\\n{blog_output}\")\n",
    "\n",
    "    return blogposts\n",
    "\n",
    "# --- Generate blog posts ---\n",
    "blog_generator = pipeline(\"text-generation\", model=blog_model, tokenizer=blog_tokenizer)\n",
    "blogposts = generate_blogposts_for_all_categories(df, generator=blog_generator)\n",
    "\n",
    "# --- Display blog posts ---\n",
    "for post in blogposts:\n",
    "    print(post)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
