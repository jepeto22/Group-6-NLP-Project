{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbae0aa4",
   "metadata": {},
   "source": [
    "## Model 2 - Product categories clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fed6ef",
   "metadata": {},
   "source": [
    "#### 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load environment variables (e.g., OpenAI API key)\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a27a5",
   "metadata": {},
   "source": [
    "#### 2. Text Vectorization (TF-IDF)\n",
    "\n",
    "This function transforms product text into a numeric format (TF-IDF matrix) so clustering can be performed on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeee348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(df, text_col='name_category_lemmatized'):\n",
    "    \"\"\"\n",
    "    Converts the text column of the dataframe into TF-IDF vectors.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input data.\n",
    "        text_col (str): Column containing preprocessed product text.\n",
    "\n",
    "    Returns:\n",
    "        X (sparse matrix): TF-IDF feature matrix.\n",
    "        vectorizer (TfidfVectorizer): The fitted vectorizer object.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(df[text_col])\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806652a2",
   "metadata": {},
   "source": [
    "#### 3. Find Optimal Number of Clusters (k)\n",
    "\n",
    "Applies the elbow method to find the best number of clusters, using KneeLocator to automatically detect the \"knee\" point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_k(X, k_range, random_state=42, plot=True):\n",
    "    \"\"\"\n",
    "    Uses the elbow method and KneeLocator to determine the optimal number of clusters.\n",
    "\n",
    "    Parameters:\n",
    "        X (sparse matrix): Feature matrix from vectorization.\n",
    "        k_range (range): Range of k values to test.\n",
    "        random_state (int): Seed for reproducibility.\n",
    "        plot (bool): Whether to show the elbow plot.\n",
    "\n",
    "    Returns:\n",
    "        optimal_k (int): Best number of clusters detected.\n",
    "    \"\"\"\n",
    "    inertias = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=10)\n",
    "        kmeans.fit(X)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(list(k_range), inertias, marker='o')\n",
    "        plt.xlabel('Number of clusters (k)')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.title('Elbow Method For Optimal k')\n",
    "        plt.show()\n",
    "\n",
    "    kneedle = KneeLocator(list(k_range), inertias, curve='convex', direction='decreasing')\n",
    "    optimal_k = kneedle.elbow - 1 if kneedle.elbow else k_range[0]\n",
    "    print(f\"Optimal number of clusters (automatic): {optimal_k}\")\n",
    "    return optimal_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925b556",
   "metadata": {},
   "source": [
    "#### 4. Apply KMeans Clustering\n",
    "\n",
    "The below function clusters the product text vectors into groups using the KMeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans(X, n_clusters, random_state=42):\n",
    "    \"\"\"\n",
    "    Applies KMeans clustering to the TF-IDF matrix.\n",
    "\n",
    "    Parameters:\n",
    "        X (sparse matrix): TF-IDF matrix.\n",
    "        n_clusters (int): Number of clusters to use.\n",
    "        random_state (int): Random seed.\n",
    "\n",
    "    Returns:\n",
    "        kmeans (KMeans): Fitted KMeans object.\n",
    "        labels (ndarray): Cluster labels for each data point.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=20)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    return kmeans, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887820bb",
   "metadata": {},
   "source": [
    "#### 5. Visualize Clusters with PCA\n",
    "\n",
    "The below function visualizes clusters in 2D using PCA to reduce the TF-IDF matrixâ€™s dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, labels, random_state=42):\n",
    "    \"\"\"\n",
    "    Reduces high-dimensional data to 2D using PCA and visualizes clusters.\n",
    "\n",
    "    Parameters:\n",
    "        X (sparse matrix or ndarray): Feature matrix.\n",
    "        labels (ndarray): Cluster assignments.\n",
    "        random_state (int): PCA seed.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2, random_state=random_state)\n",
    "    X_pca = pca.fit_transform(X.toarray() if hasattr(X, \"toarray\") else X)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for cluster_id in np.unique(labels):\n",
    "        plt.scatter(\n",
    "            X_pca[labels == cluster_id, 0],\n",
    "            X_pca[labels == cluster_id, 1],\n",
    "            label=f'Cluster {cluster_id}', alpha=0.5\n",
    "        )\n",
    "    plt.title('K-Means Clusters Visualization (PCA)')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c51da4",
   "metadata": {},
   "source": [
    "#### 6. Display Sample Products per Cluster\n",
    "\n",
    "It allow us to inspect a few representative products from each cluster for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_products(df, cluster_col='cluster'):\n",
    "    \"\"\"\n",
    "    Displays a few sample products from each cluster.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Data with assigned clusters.\n",
    "        cluster_col (str): Column name where cluster IDs are stored.\n",
    "    \"\"\"\n",
    "    for cluster_id in sorted(df[cluster_col].unique()):\n",
    "        print(f\"\\nCluster {cluster_id} sample products:\")\n",
    "        display(df[df[cluster_col] == cluster_id][['name', 'categories']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902fed36",
   "metadata": {},
   "source": [
    "#### 7. Generate Category Names with OpenAI GPT 3.5 turbo model\n",
    "\n",
    "This function sends a list of product names to the OpenAI GPT-3.5 Turbo API to get a meaningful category name.\n",
    "It avoids reusing names by checking against already used names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_name_openai(product_names, used_names, openai_api_key, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Calls OpenAI API to generate a unique, concise category name based on product names.\n",
    "\n",
    "    Parameters:\n",
    "        product_names (list): Product names within a cluster.\n",
    "        used_names (set): Set of already-used category names to avoid duplicates.\n",
    "        openai_api_key (str): Your OpenAI API key.\n",
    "        model (str): Model to use (default: gpt-3.5-turbo).\n",
    "\n",
    "    Returns:\n",
    "        str: A unique category name.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following list of product names, suggest a concise, precise category name that best describes the majority of products and is not generic. \"\n",
    "        f\"Do NOT use any of these words: {', '.join(used_names)}\\n\"\n",
    "        \"Only return the category name, nothing else.\\n\\n\"\n",
    "        \"Product names:\\n\" + \"\\n\".join(product_names)\n",
    "    )\n",
    "    client = openai.OpenAI(api_key=openai_api_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "        max_tokens=15,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a961fb",
   "metadata": {},
   "source": [
    "#### 8. Assign Generated Category Names to Clusters\n",
    "\n",
    "Maps OpenAI-generated category names to each product cluster and adds a new column (clustered_category), to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e214034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cluster_names(df, cluster_col='cluster', name_col='name', openai_api_key=None):\n",
    "    \"\"\"\n",
    "    Assigns a descriptive category name to each cluster using OpenAI.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Data containing clusters.\n",
    "        cluster_col (str): Name of the cluster column.\n",
    "        name_col (str): Column to extract product names from.\n",
    "        openai_api_key (str): OpenAI API key.\n",
    "\n",
    "    Returns:\n",
    "        df (DataFrame): Data with an added 'clustered_category' column.\n",
    "        cluster_name_map (dict): Mapping of cluster ID to category name.\n",
    "    \"\"\"\n",
    "    cluster_name_map = {}\n",
    "    used_names = set()\n",
    "    for cluster_id in sorted(df[cluster_col].unique()):\n",
    "        product_names = df[df[cluster_col] == cluster_id][name_col].dropna().unique().tolist()\n",
    "        if product_names:\n",
    "            category_name = get_category_name_openai(product_names, used_names, openai_api_key)\n",
    "            while category_name in used_names:\n",
    "                category_name = get_category_name_openai(product_names, used_names, openai_api_key)\n",
    "            used_names.add(category_name)\n",
    "            cluster_name_map[cluster_id] = category_name\n",
    "    df['clustered_category'] = df[cluster_col].map(cluster_name_map)\n",
    "    return df, cluster_name_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9290d83",
   "metadata": {},
   "source": [
    "#### 9. Full Clustering + Labeling Pipeline\n",
    "\n",
    "This is the function that combines all the steps into one: vectorization, clusterization, visualization, display, and categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_and_label_products(\n",
    "    df,\n",
    "    text_col='name_category_lemmatized',\n",
    "    k_range=range(2, 11),\n",
    "    random_state=42,\n",
    "    show_samples=True,\n",
    "    show_plot=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Full pipeline: vectorizes product text, clusters it, assigns category names via OpenAI.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Input dataframe.\n",
    "        text_col (str): Column with product text.\n",
    "        k_range (range): Range of cluster numbers to test.\n",
    "        random_state (int): Random seed.\n",
    "        show_samples (bool): Print sample products per cluster.\n",
    "        show_plot (bool): Show elbow and PCA plots.\n",
    "\n",
    "    Returns:\n",
    "        df (DataFrame): Updated with clusters and categories.\n",
    "        kmeans (KMeans): Fitted clustering model.\n",
    "        vectorizer (TfidfVectorizer): Fitted vectorizer.\n",
    "        X (sparse matrix): TF-IDF feature matrix.\n",
    "        cluster_name_map (dict): Mapping of cluster IDs to category names.\n",
    "    \"\"\"\n",
    "    # Step 1: Text vectorization\n",
    "    X, vectorizer = vectorize_text(df, text_col)\n",
    "\n",
    "    # Step 2: Find optimal number of clusters\n",
    "    optimal_k = find_optimal_k(X, k_range, random_state, plot=show_plot)\n",
    "\n",
    "    # Step 3: Cluster the data\n",
    "    kmeans, labels = apply_kmeans(X, optimal_k, random_state)\n",
    "    df['cluster'] = labels\n",
    "\n",
    "    # Step 4: Visualize results\n",
    "    if show_plot:\n",
    "        plot_clusters(X, labels, random_state)\n",
    "    if show_samples:\n",
    "        display_sample_products(df, cluster_col='cluster')\n",
    "\n",
    "    # Step 5: Name the clusters using OpenAI\n",
    "    df, cluster_name_map = assign_cluster_names(df, openai_api_key=openai_api_key)\n",
    "    print(cluster_name_map)\n",
    "    return df, kmeans, vectorizer, X, cluster_name_map"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
