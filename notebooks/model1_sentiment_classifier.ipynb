{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cdcdded",
   "metadata": {},
   "source": [
    "## Train and evaluate svm sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc35c28",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "This section imports the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_svm_sentiment(\n",
    "    df,\n",
    "    text_col='lemmatized_str',\n",
    "    label_col='sentiment',\n",
    "    ngram_range=(1,2),\n",
    "    min_df=3,\n",
    "    max_df=0.9,\n",
    "    C_grid=[0.01, 0.1, 1, 10],\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a LinearSVC sentiment classifier with TF-IDF (with ngrams) and review length as features.\n",
    "    Returns: best_model, tfidf_vectorizer, X_test_features, y_test, misclassified_df\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from scipy.sparse import hstack\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1611995",
   "metadata": {},
   "source": [
    "### Split Data into Train/Test\n",
    "Prepare the data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split\n",
    "    X_text = df[text_col]\n",
    "    y = df[label_col]\n",
    "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.2, random_state=random_state, stratify=y\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6ddc5",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization\n",
    "Convert raw text into numerical features using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fit vectorizer only on training data\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=ngram_range, min_df=min_df, max_df=max_df)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980be08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Add review length as a feature\n",
    "    train_length = np.array([len(x.split()) for x in X_train_text]).reshape(-1, 1)\n",
    "    test_length = np.array([len(x.split()) for x in X_test_text]).reshape(-1, 1)\n",
    "    X_train_features = hstack([X_train_tfidf, train_length])\n",
    "    X_test_features = hstack([X_test_tfidf, test_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14aa8c4",
   "metadata": {},
   "source": [
    "### Train SVM Model\n",
    "Train a Linear Support Vector Classifier on sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Hyperparameter tuning with GridSearchCV\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', LinearSVC())\n",
    "    ])\n",
    "    param_grid = {'clf__C': C_grid}\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "    grid.fit(X_train_features, y_train)\n",
    "    print(\"Best SVM parameters:\", grid.best_params_)\n",
    "    print(\"Best SVM F1-score (CV on train):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d38cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Cross-validation on training set\n",
    "    svc = LinearSVC(C=grid.best_params_['clf__C'], max_iter=1000, random_state=random_state)\n",
    "    scores = cross_val_score(svc, X_train_features, y_train, cv=5, scoring='f1_macro')\n",
    "    print(\"LinearSVC 5-fold CV F1-macro (train):\", scores.mean())\n",
    "    print(\"All F1-macro scores (train):\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684da62",
   "metadata": {},
   "source": [
    "### Predict Labels\n",
    "Use the trained model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Final evaluation on test set\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_features)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9091f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices of misclassified samples\n",
    "    mis_idx = np.where(y_pred != y_test)[0]\n",
    "    y_test_reset = y_test.reset_index(drop=True)\n",
    "    misclassified_df = pd.DataFrame({\n",
    "        'actual_sentiment': y_test_reset.iloc[mis_idx].values,\n",
    "        'predicted_sentiment': y_pred[mis_idx],\n",
    "        'combined_reviews': X_test_text.iloc[mis_idx].values\n",
    "    })\n",
    "    print(misclassified_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "return best_model, tfidf_vectorizer, X_test_features, y_test, misclassified_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
