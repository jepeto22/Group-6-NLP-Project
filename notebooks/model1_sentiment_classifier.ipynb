{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa72aa33",
   "metadata": {},
   "source": [
    "## Model 1 - Sentiment classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad007a",
   "metadata": {},
   "source": [
    "### 1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7bd52",
   "metadata": {},
   "source": [
    "#### 2. Prepare sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentiment_features(df, text_col='lemmatized_str', label_col='sentiment'):\n",
    "    \"\"\"\n",
    "    Prepares features and labels for sentiment classification.\n",
    "    - Splits data into train/test sets.\n",
    "    - Vectorizes text using TF-IDF.\n",
    "    - Adds review length as a feature.\n",
    "    Returns: X_train_features, X_test_features, y_train, y_test, X_test_text, tfidf_vectorizer\n",
    "    \"\"\"\n",
    "    # Prepare features and labels\n",
    "    X_text = df[text_col]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # Split data\n",
    "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Vectorize text using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    # Add review length as a feature\n",
    "    train_length = np.array([len(x.split()) for x in X_train_text]).reshape(-1, 1)\n",
    "    test_length = np.array([len(x.split()) for x in X_test_text]).reshape(-1, 1)\n",
    "    X_train_features = hstack([X_train_tfidf, train_length])\n",
    "    X_test_features = hstack([X_test_tfidf, test_length])\n",
    "    \n",
    "    return X_train_features, X_test_features, y_train, y_test, X_test_text, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c460b35",
   "metadata": {},
   "source": [
    "#### 3. Prepare list of models to iterate thorugh and find the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_models():\n",
    "    \"\"\"\n",
    "    Returns a list of tuples: (model name, model instance, parameter grid)\n",
    "    \"\"\"\n",
    "    return [\n",
    "        (\n",
    "            \"Logistic Regression\",\n",
    "            LogisticRegression(max_iter=2000, random_state=42),\n",
    "            {'C': [0.01, 0.1, 1, 10]}\n",
    "        ),\n",
    "        (\n",
    "            \"Linear SVC\",\n",
    "            LinearSVC(max_iter=1000, random_state=42),\n",
    "            {'C': [0.01, 0.1, 1, 10]}\n",
    "        ),\n",
    "        (\n",
    "            \"Random Forest\",\n",
    "            RandomForestClassifier(random_state=42),\n",
    "            {'n_estimators': [50, 100], 'max_depth': [None, 10, 20]}\n",
    "        ),\n",
    "        (\n",
    "            \"Multinomial NB\",\n",
    "            MultinomialNB(),\n",
    "            {'alpha': [0.5, 1.0, 2.0]}\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c1f491",
   "metadata": {},
   "source": [
    "#### 3. Training the best sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ba32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_sentiment_model(X_train, y_train, models_and_grids):\n",
    "    \"\"\"\n",
    "    Trains models using GridSearchCV and selects the best one based on F1-macro score.\n",
    "    Returns: (best_model_name, best_score, best_model, results_list)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for name, model, param_grid in models_and_grids:\n",
    "        print(f\"\\n{name} - GridSearchCV\")\n",
    "        grid = GridSearchCV(model, param_grid, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "        try:\n",
    "            grid.fit(X_train, y_train)\n",
    "            print(\"Best params:\", grid.best_params_)\n",
    "            print(\"Best CV F1-macro:\", grid.best_score_)\n",
    "            results.append((name, grid.best_score_, grid.best_estimator_))\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {e}\")\n",
    "    if results:\n",
    "        best_name, best_score, best_model = max(results, key=lambda x: x[1])\n",
    "        return best_name, best_score, best_model, results\n",
    "    else:\n",
    "        return None, None, None, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b637c",
   "metadata": {},
   "source": [
    "#### 4. Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentiment_model(model, X_test, y_test, X_test_text):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set and prints classification report and confusion matrix, as well as showing the missclassified examples.\n",
    "    Returns: y_pred, misclassified_df\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    mis_idx = np.where(y_pred != y_test)[0]\n",
    "    y_test_reset = y_test.reset_index(drop=True)\n",
    "    misclassified_df = pd.DataFrame({\n",
    "        'actual_sentiment': y_test_reset.iloc[mis_idx].values,\n",
    "        'predicted_sentiment': y_pred[mis_idx],\n",
    "        'combined_reviews': X_test_text.iloc[mis_idx].values\n",
    "    })\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(misclassified_df.head())\n",
    "    return y_pred, misclassified_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
